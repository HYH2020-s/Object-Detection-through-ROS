{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://pjreddie.com/darknet/yolo/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gets configuration files\n",
    "```\n",
    "git clone https://github.com/pjreddie/darknet\n",
    "copy darknet/cfg/yolov3.cfg -P ./cfg\n",
    "copy darknet/cfg/yolo3-tiny.cfg -P ./cfg\n",
    "```\n",
    "\n",
    "#### gets weights files\n",
    "```\n",
    "wget https://pjreddie.com/media/files/yolov3.weights -P ./weights\n",
    "wget https://pjreddie.com/media/files/yolov3-tiny.weights -P ./weights\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv3 & YOLOv3-TINY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: [Object Detection using YoloV3 and OpenCV](https://towardsdatascience.com/object-detection-using-yolov3-and-opencv-19ee0792a420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo(weights_file, cfg_file):\n",
    "    net = cv2.dnn.readNet(weights_file, cfg_file)\n",
    "    classes = []\n",
    "    with open(\"data/coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layers_names = net.getLayerNames()\n",
    "    output_layers = [layers_names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "    return net, classes, colors, output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_file):\n",
    "    # image loading\n",
    "    img = cv2.imread(img_file)\n",
    "    height, width, channels = img.shape\n",
    "    return img, height, width, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img, net, outputLayers, size):            \n",
    "    blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=size, mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(outputLayers)\n",
    "    return blob, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_dimensions(outputs, height, width):\n",
    "    boxes = []\n",
    "    confs = []\n",
    "    class_ids = []\n",
    "    for output in outputs:\n",
    "        for detect in output:\n",
    "            scores = detect[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            conf = scores[class_id]\n",
    "            if conf > 0.3:\n",
    "                center_x = int(detect[0] * width)\n",
    "                center_y = int(detect[1] * height)\n",
    "                w = int(detect[2] * width)\n",
    "                h = int(detect[3] * height)\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confs.append(float(conf))\n",
    "                class_ids.append(class_id)\n",
    "    return boxes, confs, class_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_points(p):\n",
    "    p1 = p[:2]\n",
    "    p2 = [p[0] + p[2], p[1] + p[3]]\n",
    "    return p[:2] + [p[0] + p[2], p[1] + p[3]]\n",
    "\n",
    "def batch_prediction(yolo_version, print_progress = True): \n",
    "\n",
    "    # loads a model\n",
    "    weights_path = \"/Users/chanho/Documents/GitLab/niceface/evaluation/weights/\"\n",
    "    weights_name = yolo_version + '.weights'\n",
    "    weights_file = weights_path + weights_name\n",
    "\n",
    "    cfg_path = \"/Users/chanho/Documents/GitLab/niceface/evaluation/cfg/\"\n",
    "    cfg_name = yolo_version + '.cfg'\n",
    "    cfg_file = cfg_path + cfg_name\n",
    "\n",
    "    if yolo_version == 'yolov3':\n",
    "        img_size = (416, 416)\n",
    "    elif yolo_version == 'yolov3-tiny':\n",
    "        img_size = (320, 320)\n",
    "\n",
    "    model, classes, colors, output_layers = load_yolo(weights_file, cfg_file)\n",
    "    if print_progress:\n",
    "        print('%s is loaded.' % (yolo_version))\n",
    "    \n",
    "    # detects objects\n",
    "    img_path = '/Users/chanho/Documents/GitLab/niceface/evaluation/testset-img/'\n",
    "    img_names = [f for f in listdir(img_path) if f.endswith('.jpg')]\n",
    "\n",
    "    result_dict = {}\n",
    "    label = ['person', 'car']\n",
    "    for l in label:\n",
    "        result_dict[l] = {}\n",
    "        for f in img_names:\n",
    "            img_file = img_path + f\n",
    "            image, height, width, channels = load_image(img_file)\n",
    "            blob, outputs = detect_objects(image, model, output_layers, img_size)\n",
    "            boxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "            indexes = cv2.dnn.NMSBoxes(boxes, confs, 0.5, 0.4)\n",
    "\n",
    "            result_dict[l][f] = {}\n",
    "            result_dict[l][f]['boxes'] = []\n",
    "            result_dict[l][f]['scores'] = []\n",
    "            for i, c in enumerate(class_ids):\n",
    "                if i in indexes:\n",
    "                    if (l == 'person' and c == 0) or (l == 'car' and c in [2, 5, 7]): # car, bus, truck\n",
    "                        result_dict[l][f]['boxes'].append(convert_points(boxes[i]))\n",
    "                        result_dict[l][f]['scores'].append(confs[i])\n",
    "        if print_progress:\n",
    "            print('%s is predicted in %d images.' % (l, len(img_names)))\n",
    "            \n",
    "    # writes results\n",
    "    det_dir = '/Users/chanho/Documents/GitLab/niceface/evaluation/predicted_boxes/'\n",
    "    for l in label:\n",
    "        with open(det_dir+'/predicted_boxes-'+yolo_version+'-'+l+'.json', 'w') as fp:\n",
    "            json.dump(result_dict[l], fp)\n",
    "        if print_progress:\n",
    "            print('%s is writeen.' % (l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov3 is loaded.\n",
      "person is predicted in 100 images.\n",
      "car is predicted in 100 images.\n",
      "person is writeen.\n",
      "car is writeen.\n",
      "yolov3-tiny is loaded.\n",
      "person is predicted in 100 images.\n",
      "car is predicted in 100 images.\n",
      "person is writeen.\n",
      "car is writeen.\n"
     ]
    }
   ],
   "source": [
    "batch_prediction('yolov3', print_progress = True)\n",
    "batch_prediction('yolov3-tiny', print_progress = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
